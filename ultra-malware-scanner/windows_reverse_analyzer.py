#!/usr/bin/env python3
"""
Windows-Compatible Complete Reverse Engineering Analyzer
Comprehensive tool for reverse engineering analysis with automated reporting
"""

import os
import sys
import json
import shutil
import argparse
import subprocess
import datetime
from pathlib import Path
import hashlib
import requests
import time
import re
import threading

# Terminal colors for better visualization
class Colors:
    RED = '\033[91m'
    GREEN = '\033[92m'
    YELLOW = '\033[93m'
    BLUE = '\033[94m'
    MAGENTA = '\033[95m'
    CYAN = '\033[96m'
    WHITE = '\033[97m'
    BOLD = '\033[1m'
    UNDERLINE = '\033[4m'
    END = '\033[0m'
    
    @staticmethod
    def colorize(text, color):
        return f"{color}{text}{Colors.END}"

class WindowsReverseAnalyzer:
    def __init__(self, gemini_api_key=None):
        self.gemini_api_key = gemini_api_key
        self.test_folder = "test_analysis"
        self.reports_folder = "reports"
        self.timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        self.results = {
            "metadata": {},
            "file_info": {},
            "analysis_results": {},
            "security_findings": [],
            "recommendations": [],
            "timestamp": self.timestamp
        }
        self.live_findings = []
        
    def print_banner(self):
        """Print analysis banner"""
        banner = f"""
{Colors.CYAN}{'='*80}
{Colors.BOLD}üîç WINDOWS REVERSE ENGINEERING ANALYZER{Colors.END}
{Colors.CYAN}{'='*80}{Colors.END}
{Colors.YELLOW}‚ö° Real-time Security Analysis with Live Findings{Colors.END}
{Colors.CYAN}{'='*80}{Colors.END}
        """
        print(banner)
        
    def print_section_header(self, title, icon="üîß"):
        """Print colored section header"""
        print(f"\n{Colors.BLUE}{Colors.BOLD}{icon} {title.upper()}{Colors.END}")
        print(f"{Colors.BLUE}{'‚îÄ' * (len(title) + 4)}{Colors.END}")
        
    def print_finding(self, finding_type, severity, description, details=None):
        """Print real-time finding with color coding"""
        severity_colors = {
            "HIGH": Colors.RED,
            "MEDIUM": Colors.YELLOW,
            "LOW": Colors.GREEN,
            "INFO": Colors.CYAN
        }
        
        severity_icons = {
            "HIGH": "üö®",
            "MEDIUM": "‚ö†Ô∏è",
            "LOW": "‚ÑπÔ∏è",
            "INFO": "üìã"
        }
        
        color = severity_colors.get(severity, Colors.WHITE)
        icon = severity_icons.get(severity, "‚Ä¢")
        
        print(f"{color}{Colors.BOLD}{icon} [{severity}] {finding_type}{Colors.END}")
        print(f"   {Colors.WHITE}{description}{Colors.END}")
        
        if details:
            for detail in details:
                print(f"   {Colors.CYAN}‚îî‚îÄ {detail}{Colors.END}")
        
        # Store for summary
        self.live_findings.append({
            "type": finding_type,
            "severity": severity,
            "description": description,
            "details": details or []
        })
        
    def print_progress(self, message, status="RUNNING"):
        """Print progress with status indicator"""
        status_colors = {
            "RUNNING": Colors.YELLOW,
            "SUCCESS": Colors.GREEN,
            "FAILED": Colors.RED,
            "INFO": Colors.CYAN
        }
        
        status_icons = {
            "RUNNING": "‚è≥",
            "SUCCESS": "‚úÖ",
            "FAILED": "‚ùå",
            "INFO": "‚ÑπÔ∏è"
        }
        
        color = status_colors.get(status, Colors.WHITE)
        icon = status_icons.get(status, "‚Ä¢")
        
        print(f"{color}{icon} {message}{Colors.END}")
        
    def print_live_summary(self):
        """Print live findings summary"""
        if not self.live_findings:
            return
            
        print(f"\n{Colors.MAGENTA}{Colors.BOLD}üìä LIVE FINDINGS SUMMARY{Colors.END}")
        print(f"{Colors.MAGENTA}{'‚îÄ' * 25}{Colors.END}")
        
        # Count by severity
        severity_counts = {"HIGH": 0, "MEDIUM": 0, "LOW": 0, "INFO": 0}
        for finding in self.live_findings:
            severity_counts[finding["severity"]] += 1
            
        # Display counts with colors
        for severity, count in severity_counts.items():
            if count > 0:
                color = {
                    "HIGH": Colors.RED,
                    "MEDIUM": Colors.YELLOW,
                    "LOW": Colors.GREEN,
                    "INFO": Colors.CYAN
                }[severity]
                print(f"{color}‚Ä¢ {severity}: {count} findings{Colors.END}")
                
    def show_file_analysis_header(self, filename, file_info):
        """Show file analysis header with key info"""
        print(f"\n{Colors.GREEN}{Colors.BOLD}üìÑ ANALYZING FILE: {filename}{Colors.END}")
        print(f"{Colors.GREEN}{'‚îÄ' * (len(filename) + 18)}{Colors.END}")
        print(f"{Colors.CYAN}üìè Size: {file_info.get('size', 'Unknown')} bytes{Colors.END}")
        print(f"{Colors.CYAN}üîç Type: {file_info.get('file_type', 'Unknown')}{Colors.END}")
        print(f"{Colors.CYAN}üîê MD5: {file_info.get('md5', 'Unknown')[:16]}...{Colors.END}")
        print(f"{Colors.CYAN}üîê SHA256: {file_info.get('sha256', 'Unknown')[:16]}...{Colors.END}")
        
    def setup_environment(self):
        """Setup test and reports directories"""
        os.makedirs(self.test_folder, exist_ok=True)
        os.makedirs(self.reports_folder, exist_ok=True)
        print(f"[+] Created directories: {self.test_folder}, {self.reports_folder}")
        
    def copy_target_file(self, source_path):
        """Copy target file to test folder"""
        if not os.path.exists(source_path):
            raise FileNotFoundError(f"Target file not found: {source_path}")
            
        filename = os.path.basename(source_path)
        target_path = os.path.join(self.test_folder, filename)
        shutil.copy2(source_path, target_path)
        
        print(f"[+] Copied {source_path} to {target_path}")
        return target_path, filename
        
    def get_file_info(self, file_path):
        """Extract basic file information"""
        try:
            stat = os.stat(file_path)
            with open(file_path, 'rb') as f:
                content = f.read()
                
            file_info = {
                "filename": os.path.basename(file_path),
                "size": stat.st_size,
                "md5": hashlib.md5(content).hexdigest(),
                "sha256": hashlib.sha256(content).hexdigest(),
                "created": datetime.datetime.fromtimestamp(stat.st_ctime).isoformat(),
                "modified": datetime.datetime.fromtimestamp(stat.st_mtime).isoformat(),
            }
            
            # Determine file type based on content and extension
            try:
                # Try to decode as text
                text_content = content.decode('utf-8', errors='ignore')
                file_info["is_text"] = True
                file_info["text_content"] = text_content
                file_info["mime_type"] = "text/plain"
                file_info["file_type"] = "text file"
            except:
                file_info["is_text"] = False
                file_info["mime_type"] = "application/octet-stream"
                file_info["file_type"] = "binary file"
                
            return file_info
        except Exception as e:
            return {"error": str(e)}
            
    def run_strings_analysis(self, file_path):
        """Run strings analysis using Python with real-time feedback"""
        try:
            self.print_section_header("String Analysis", "üî§")
            self.print_progress("Extracting printable strings from file...", "RUNNING")
            
            with open(file_path, 'rb') as f:
                content = f.read()
            
            # Extract printable strings (4+ characters)
            strings = []
            current_string = ""
            
            for byte in content:
                if 32 <= byte <= 126:  # Printable ASCII
                    current_string += chr(byte)
                else:
                    if len(current_string) >= 4:
                        strings.append(current_string)
                    current_string = ""
            
            # Add final string if valid
            if len(current_string) >= 4:
                strings.append(current_string)
            
            self.print_progress(f"Found {len(strings)} printable strings", "SUCCESS")
            
            # Filter for interesting strings with real-time reporting
            interesting_strings = []
            suspicious_keywords = [
                'password', 'key', 'secret', 'token', 'api', 'url', 'http', 'https',
                'ftp', 'sql', 'admin', 'root', 'config', 'debug', 'CreateRemoteThread',
                'WriteProcessMemory', 'VirtualAlloc', 'LoadLibrary', 'GetProcAddress',
                'CryptEncrypt', 'AES', 'SHA256', 'malicious', 'HKEY_', 'Registry'
            ]
            
            self.print_progress("Analyzing strings for suspicious content...", "RUNNING")
            
            for string in strings:
                for keyword in suspicious_keywords:
                    if keyword.lower() in string.lower():
                        risk_level = self.assess_string_risk(string, keyword)
                        interesting_strings.append({
                            "string": string,
                            "keyword_matched": keyword,
                            "risk_level": risk_level
                        })
                        
                        # Real-time finding report
                        self.print_finding(
                            f"Suspicious String: {keyword}",
                            risk_level,
                            f"Found suspicious keyword '{keyword}' in string",
                            [f"String: {string[:80]}..." if len(string) > 80 else f"String: {string}"]
                        )
                        break
            
            if interesting_strings:
                self.print_progress(f"Identified {len(interesting_strings)} suspicious strings", "SUCCESS")
            else:
                self.print_progress("No suspicious strings detected", "INFO")
                        
            return {
                "total_strings": len(strings),
                "all_strings": strings[:100],  # Limit output
                "interesting_strings": interesting_strings,
                "status": "success"
            }
        except Exception as e:
            self.print_progress(f"String analysis failed: {str(e)}", "FAILED")
            return {"error": str(e), "status": "failed"}
            
    def assess_string_risk(self, string, keyword):
        """Assess risk level of a string"""
        high_risk_keywords = ['CreateRemoteThread', 'WriteProcessMemory', 'VirtualAlloc', 
                             'password', 'secret', 'key']
        medium_risk_keywords = ['http', 'https', 'Registry', 'HKEY_', 'CryptEncrypt']
        
        if any(k.lower() in keyword.lower() for k in high_risk_keywords):
            return "HIGH"
        elif any(k.lower() in keyword.lower() for k in medium_risk_keywords):
            return "MEDIUM"
        else:
            return "LOW"
            
    def run_hexdump_analysis(self, file_path):
        """Run hexdump analysis using Python"""
        try:
            print("[+] Running hexdump analysis...")
            
            with open(file_path, 'rb') as f:
                content = f.read()
            
            hex_lines = []
            for i in range(0, min(len(content), 1024), 16):  # First 1KB
                chunk = content[i:i+16]
                hex_part = ' '.join(f'{b:02x}' for b in chunk)
                ascii_part = ''.join(chr(b) if 32 <= b <= 126 else '.' for b in chunk)
                hex_lines.append(f"{i:08x}  {hex_part:<48} |{ascii_part}|")
                
            return {
                "hex_preview": hex_lines,
                "total_bytes": len(content),
                "status": "success"
            }
        except Exception as e:
            return {"error": str(e), "status": "failed"}
            
    def run_pattern_analysis(self, file_path):
        """Run pattern analysis for suspicious indicators with real-time feedback"""
        try:
            self.print_section_header("Pattern Analysis", "üîç")
            self.print_progress("Scanning file for suspicious patterns...", "RUNNING")
            
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
            
            patterns = {
                "ip_addresses": (r'\b(?:[0-9]{1,3}\.){3}[0-9]{1,3}\b', "IP Addresses", "MEDIUM"),
                "urls": (r'https?://[^\s<>"{}|\\^`\[\]]+', "URLs", "MEDIUM"),
                "email_addresses": (r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', "Email Addresses", "LOW"),
                "registry_keys": (r'HKEY_[A-Z_]+\\[^\\]+(?:\\[^\\]+)*', "Registry Keys", "MEDIUM"),
                "file_paths": (r'[A-Za-z]:\\(?:[^\\/:*?"<>|\r\n]+\\)*[^\\/:*?"<>|\r\n]*', "File Paths", "LOW"),
                "api_functions": (r'\b(?:CreateRemoteThread|WriteProcessMemory|VirtualAlloc|LoadLibrary|GetProcAddress|CryptEncrypt)\b', "API Functions", "HIGH"),
                "crypto_indicators": (r'\b(?:AES|SHA256|MD5|RSA|DES|RC4)\b', "Crypto Indicators", "MEDIUM")
            }
            
            findings = {}
            total_patterns_found = 0
            
            for pattern_name, (pattern, display_name, severity) in patterns.items():
                matches = re.findall(pattern, content, re.IGNORECASE)
                if matches:
                    unique_matches = list(set(matches))[:10]  # Unique matches, limit to 10
                    findings[pattern_name] = {
                        "count": len(matches),
                        "matches": unique_matches
                    }
                    total_patterns_found += len(matches)
                    
                    # Real-time finding report
                    self.print_finding(
                        f"{display_name} Detected",
                        severity,
                        f"Found {len(matches)} {display_name.lower()} in file",
                        [f"Examples: {', '.join(unique_matches[:3])}"]
                    )
            
            if total_patterns_found > 0:
                self.print_progress(f"Pattern analysis complete - {total_patterns_found} total patterns found", "SUCCESS")
            else:
                self.print_progress("No suspicious patterns detected", "INFO")
                    
            return {
                "patterns_found": findings,
                "status": "success"
            }
        except Exception as e:
            self.print_progress(f"Pattern analysis failed: {str(e)}", "FAILED")
            return {"error": str(e), "status": "failed"}
            
    def run_entropy_analysis(self, file_path):
        """Calculate file entropy to detect encryption/compression"""
        try:
            print("[+] Running entropy analysis...")
            
            with open(file_path, 'rb') as f:
                content = f.read()
            
            if len(content) == 0:
                return {"entropy": 0, "status": "success"}
            
            # Calculate Shannon entropy
            byte_counts = [0] * 256
            for byte in content:
                byte_counts[byte] += 1
                
            entropy = 0
            for count in byte_counts:
                if count > 0:
                    probability = count / len(content)
                    entropy -= probability * (probability * 8).bit_length() / 8
                    
            # Assess entropy level
            if entropy > 7.5:
                entropy_level = "HIGH (likely encrypted/compressed)"
            elif entropy > 6.0:
                entropy_level = "MEDIUM (mixed content)"
            else:
                entropy_level = "LOW (likely text/structured data)"
                
            return {
                "entropy": entropy,
                "entropy_level": entropy_level,
                "file_size": len(content),
                "status": "success"
            }
        except Exception as e:
            return {"error": str(e), "status": "failed"}         
   
    def analyze_security_risks(self, analysis_results):
        """Analyze security risks from all results"""
        risks = []
        
        # Check strings for sensitive data
        if "strings" in analysis_results and "interesting_strings" in analysis_results["strings"]:
            for string_info in analysis_results["strings"]["interesting_strings"]:
                if string_info["risk_level"] == "HIGH":
                    risks.append({
                        "type": "High-Risk API Function",
                        "severity": "HIGH",
                        "description": f"Suspicious API function found: {string_info['string']}",
                        "recommendation": "Investigate the context and purpose of this API call",
                        "impact": "Could indicate malicious behavior or code injection attempts"
                    })
                elif string_info["risk_level"] == "MEDIUM":
                    risks.append({
                        "type": "Potentially Suspicious Content",
                        "severity": "MEDIUM", 
                        "description": f"Potentially suspicious string: {string_info['string']}",
                        "recommendation": "Review the context and validate legitimacy",
                        "impact": "May indicate network communication or system access"
                    })
        
        # Check pattern analysis results
        if "pattern_analysis" in analysis_results and "patterns_found" in analysis_results["pattern_analysis"]:
            patterns = analysis_results["pattern_analysis"]["patterns_found"]
            
            if "api_functions" in patterns:
                risks.append({
                    "type": "Suspicious API Functions",
                    "severity": "HIGH",
                    "description": f"Found {patterns['api_functions']['count']} suspicious API function references",
                    "recommendation": "Analyze the context of these API calls for malicious intent",
                    "impact": "High risk of process injection, memory manipulation, or code execution"
                })
                
            if "urls" in patterns:
                risks.append({
                    "type": "Network Indicators",
                    "severity": "MEDIUM",
                    "description": f"Found {patterns['urls']['count']} URL references",
                    "recommendation": "Verify if these URLs are legitimate and safe",
                    "impact": "Potential data exfiltration or command and control communication"
                })
                
            if "registry_keys" in patterns:
                risks.append({
                    "type": "Registry Manipulation",
                    "severity": "MEDIUM",
                    "description": f"Found {patterns['registry_keys']['count']} registry key references",
                    "recommendation": "Check if registry modifications are authorized",
                    "impact": "Could indicate persistence mechanisms or system configuration changes"
                })
        
        # Check entropy analysis
        if "entropy" in analysis_results and analysis_results["entropy"]["status"] == "success":
            entropy = analysis_results["entropy"]["entropy"]
            if entropy > 7.5:
                risks.append({
                    "type": "High Entropy Content",
                    "severity": "MEDIUM",
                    "description": f"File has high entropy ({entropy:.2f}), indicating possible encryption or compression",
                    "recommendation": "Investigate if encryption/compression is expected for this file type",
                    "impact": "May hide malicious content or indicate data obfuscation"
                })
                
        return risks
        
    def generate_recommendations(self, analysis_results, security_risks):
        """Generate security recommendations"""
        recommendations = []
        
        # General recommendations
        recommendations.extend([
            {
                "category": "Analysis Environment",
                "recommendation": "Always analyze unknown files in isolated virtual machines or sandboxes",
                "priority": "HIGH",
                "rationale": "Prevents potential system compromise during analysis"
            },
            {
                "category": "Multi-Engine Scanning",
                "recommendation": "Scan files with multiple antivirus engines (VirusTotal, etc.) before analysis",
                "priority": "HIGH",
                "rationale": "Provides broader detection coverage for known threats"
            },
            {
                "category": "Documentation",
                "recommendation": "Document all findings and maintain detailed analysis logs",
                "priority": "MEDIUM",
                "rationale": "Enables knowledge sharing and future reference"
            }
        ])
        
        # Risk-specific recommendations
        high_risk_count = sum(1 for risk in security_risks if risk["severity"] == "HIGH")
        medium_risk_count = sum(1 for risk in security_risks if risk["severity"] == "MEDIUM")
        
        if high_risk_count > 0:
            recommendations.append({
                "category": "Immediate Action",
                "recommendation": f"Address {high_risk_count} high-severity security findings immediately",
                "priority": "CRITICAL",
                "rationale": "High-risk findings indicate potential malicious activity"
            })
            
        if medium_risk_count > 0:
            recommendations.append({
                "category": "Investigation",
                "recommendation": f"Investigate {medium_risk_count} medium-severity findings for context validation",
                "priority": "HIGH",
                "rationale": "Medium-risk findings may indicate suspicious but not necessarily malicious activity"
            })
            
        # Pattern-specific recommendations
        if "pattern_analysis" in analysis_results:
            patterns = analysis_results["pattern_analysis"].get("patterns_found", {})
            
            if "api_functions" in patterns:
                recommendations.append({
                    "category": "Code Analysis",
                    "recommendation": "Perform dynamic analysis to observe API function behavior",
                    "priority": "HIGH",
                    "rationale": "Understanding API usage context is crucial for threat assessment"
                })
                
            if "urls" in patterns:
                recommendations.append({
                    "category": "Network Security",
                    "recommendation": "Block identified URLs at network perimeter until verified safe",
                    "priority": "HIGH",
                    "rationale": "Prevents potential data exfiltration or malware communication"
                })
                
        return recommendations
        
    def generate_html_report(self, json_data):
        """Generate comprehensive HTML report"""
        try:
            print("[+] Generating comprehensive HTML report...")
            
            # Get Gemini API analysis for executive summary
            executive_summary = ""
            if self.gemini_api_key:
                executive_summary = self.get_gemini_analysis(json_data)
            
            if not executive_summary:
                executive_summary = self.generate_default_executive_summary(json_data)
            
            html_content = f"""<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Security Analysis Report - {json_data['file_info']['filename']}</title>
    <style>
        body {{
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            background-color: #f5f5f5;
            color: #333;
        }}
        .container {{
            max-width: 1200px;
            margin: 0 auto;
            background-color: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 0 20px rgba(0,0,0,0.1);
        }}
        h1 {{
            color: #2c3e50;
            border-bottom: 3px solid #3498db;
            padding-bottom: 10px;
            margin-bottom: 30px;
        }}
        h2 {{
            color: #34495e;
            margin-top: 40px;
            margin-bottom: 20px;
            border-left: 4px solid #3498db;
            padding-left: 15px;
        }}
        h3 {{
            color: #2c3e50;
            margin-top: 25px;
        }}
        .nav {{
            background-color: #2c3e50;
            padding: 15px;
            border-radius: 5px;
            margin-bottom: 30px;
        }}
        .nav a {{
            color: white;
            text-decoration: none;
            margin-right: 20px;
            padding: 8px 12px;
            border-radius: 3px;
            transition: background-color 0.3s;
        }}
        .nav a:hover {{
            background-color: #34495e;
        }}
        table {{
            width: 100%;
            border-collapse: collapse;
            margin-bottom: 25px;
            background-color: white;
        }}
        th, td {{
            border: 1px solid #ddd;
            padding: 12px;
            text-align: left;
        }}
        th {{
            background-color: #f8f9fa;
            font-weight: bold;
            color: #2c3e50;
        }}
        .severity-high {{
            background-color: #ffebee;
            color: #c62828;
            font-weight: bold;
        }}
        .severity-medium {{
            background-color: #fff3e0;
            color: #ef6c00;
            font-weight: bold;
        }}
        .severity-low {{
            background-color: #e8f5e8;
            color: #2e7d32;
            font-weight: bold;
        }}
        .risk-score {{
            font-size: 24px;
            font-weight: bold;
            padding: 15px;
            border-radius: 5px;
            text-align: center;
            margin: 20px 0;
        }}
        .risk-high {{
            background-color: #ffebee;
            color: #c62828;
            border: 2px solid #c62828;
        }}
        .risk-medium {{
            background-color: #fff3e0;
            color: #ef6c00;
            border: 2px solid #ef6c00;
        }}
        .risk-low {{
            background-color: #e8f5e8;
            color: #2e7d32;
            border: 2px solid #2e7d32;
        }}
        .code-block {{
            background-color: #f8f9fa;
            border: 1px solid #e9ecef;
            border-radius: 5px;
            padding: 15px;
            font-family: 'Courier New', monospace;
            font-size: 12px;
            overflow-x: auto;
            margin: 15px 0;
        }}
        .finding-card {{
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 15px;
            margin: 15px 0;
            background-color: #fafafa;
        }}
        .metadata-grid {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }}
        .metadata-item {{
            background-color: #f8f9fa;
            padding: 15px;
            border-radius: 5px;
            border-left: 4px solid #3498db;
        }}
        .status-success {{ color: #28a745; font-weight: bold; }}
        .status-failed {{ color: #dc3545; font-weight: bold; }}
        .priority-critical {{ color: #dc3545; font-weight: bold; }}
        .priority-high {{ color: #fd7e14; font-weight: bold; }}
        .priority-medium {{ color: #ffc107; font-weight: bold; }}
        @media (max-width: 768px) {{
            .container {{ padding: 15px; }}
            .nav a {{ display: block; margin: 5px 0; }}
            table {{ font-size: 14px; }}
        }}
    </style>
</head>
<body>
    <div class="container">
        <h1>üîç Security Analysis Report</h1>
        
        <div class="nav">
            <a href="#executive-summary">Executive Summary</a>
            <a href="#file-information">File Information</a>
            <a href="#analysis-results">Analysis Results</a>
            <a href="#security-findings">Security Findings</a>
            <a href="#recommendations">Recommendations</a>
            <a href="#technical-details">Technical Details</a>
        </div>

        <section id="executive-summary">
            <h2>üìã Executive Summary</h2>
            <div class="risk-score risk-{json_data['risk_assessment']['risk_level'].lower()}">
                Risk Level: {json_data['risk_assessment']['risk_level']} 
                (Score: {json_data['risk_assessment']['overall_risk_score']})
            </div>
            {executive_summary}
        </section>

        <section id="file-information">
            <h2>üìÑ File Information</h2>
            <div class="metadata-grid">
                <div class="metadata-item">
                    <strong>Filename:</strong><br>{json_data['file_info']['filename']}
                </div>
                <div class="metadata-item">
                    <strong>Size:</strong><br>{json_data['file_info']['size']} bytes
                </div>
                <div class="metadata-item">
                    <strong>File Type:</strong><br>{json_data['file_info']['file_type']}
                </div>
                <div class="metadata-item">
                    <strong>MIME Type:</strong><br>{json_data['file_info']['mime_type']}
                </div>
            </div>
            
            <table>
                <tr><th>Property</th><th>Value</th></tr>
                <tr><td>MD5 Hash</td><td><code>{json_data['file_info']['md5']}</code></td></tr>
                <tr><td>SHA256 Hash</td><td><code>{json_data['file_info']['sha256']}</code></td></tr>
                <tr><td>Created</td><td>{json_data['file_info']['created']}</td></tr>
                <tr><td>Modified</td><td>{json_data['file_info']['modified']}</td></tr>
                <tr><td>Is Text File</td><td>{'Yes' if json_data['file_info'].get('is_text', False) else 'No'}</td></tr>
            </table>
        </section>

        <section id="analysis-results">
            <h2>üî¨ Analysis Results</h2>
            {self.generate_analysis_results_html(json_data['analysis_results'])}
        </section>

        <section id="security-findings">
            <h2>‚ö†Ô∏è Security Findings</h2>
            {self.generate_security_findings_html(json_data['security_findings'])}
        </section>

        <section id="recommendations">
            <h2>üí° Recommendations</h2>
            {self.generate_recommendations_html(json_data['recommendations'])}
        </section>

        <section id="technical-details">
            <h2>üîß Technical Details</h2>
            <h3>Raw Analysis Data</h3>
            <div class="code-block">
                <pre>{json.dumps(json_data, indent=2, default=str)}</pre>
            </div>
        </section>

        <footer style="margin-top: 50px; padding-top: 20px; border-top: 1px solid #ddd; text-align: center; color: #666;">
            <p>Report generated on {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')} by Windows Reverse Analyzer</p>
        </footer>
    </div>
</body>
</html>"""
            
            return html_content
            
        except Exception as e:
            print(f"[-] Error generating HTML report: {str(e)}")
            return None
            
    def get_gemini_analysis(self, json_data):
        """Get Gemini API analysis for executive summary"""
        try:
            prompt = f"""
            Analyze this security analysis data and provide a professional executive summary in HTML format.
            Focus on:
            1. Key security findings and their implications
            2. Risk assessment and business impact
            3. Critical recommendations
            4. Overall threat level assessment
            
            Data: {json.dumps(json_data, indent=2)}
            
            Provide only the HTML content for the executive summary section (no full HTML document).
            """
            
            url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={self.gemini_api_key}"
            
            headers = {"Content-Type": "application/json"}
            data = {
                "contents": [{
                    "parts": [{"text": prompt}]
                }]
            }
            
            response = requests.post(url, headers=headers, json=data, timeout=60)
            
            if response.status_code == 200:
                result = response.json()
                if "candidates" in result and len(result["candidates"]) > 0:
                    return result["candidates"][0]["content"]["parts"][0]["text"]
            
            return None
        except Exception as e:
            print(f"[-] Error getting Gemini analysis: {str(e)}")
            return None
    
    def generate_default_executive_summary(self, json_data):
        """Generate default executive summary if Gemini API fails"""
        risk_level = json_data['risk_assessment']['risk_level']
        risk_score = json_data['risk_assessment']['overall_risk_score']
        high_findings = json_data['risk_assessment']['high_severity_findings']
        medium_findings = json_data['risk_assessment']['medium_severity_findings']
        
        summary = f"""
        <p>This security analysis of <strong>{json_data['file_info']['filename']}</strong> reveals a <strong>{risk_level}</strong> risk level with an overall risk score of <strong>{risk_score}</strong>.</p>
        
        <h3>Key Findings:</h3>
        <ul>
            <li><strong>High Severity Issues:</strong> {high_findings}</li>
            <li><strong>Medium Severity Issues:</strong> {medium_findings}</li>
            <li><strong>File Size:</strong> {json_data['file_info']['size']} bytes</li>
            <li><strong>File Type:</strong> {json_data['file_info']['file_type']}</li>
        </ul>
        
        <h3>Risk Assessment:</h3>
        <p>Based on the analysis, this file {'requires immediate attention' if risk_level == 'HIGH' else 'should be monitored' if risk_level == 'MEDIUM' else 'appears to be low risk'}.</p>
        """
        
        return summary
    
    def generate_analysis_results_html(self, analysis_results):
        """Generate HTML for analysis results section"""
        html = ""
        
        for tool_name, results in analysis_results.items():
            status_class = "status-success" if results.get("status") == "success" else "status-failed"
            html += f"""
            <h3>üîß {tool_name.title()} Analysis</h3>
            <p>Status: <span class="{status_class}">{results.get('status', 'unknown').upper()}</span></p>
            """
            
            if results.get("status") == "success":
                if tool_name == "strings":
                    html += f"""
                    <p><strong>Total Strings Found:</strong> {results.get('total_strings', 0)}</p>
                    <p><strong>Interesting Strings:</strong> {len(results.get('interesting_strings', []))}</p>
                    """
                    if results.get('interesting_strings'):
                        html += "<table><tr><th>String</th><th>Keyword</th><th>Risk Level</th></tr>"
                        for string_info in results['interesting_strings'][:10]:
                            risk_class = f"severity-{string_info['risk_level'].lower()}"
                            html += f"""
                            <tr>
                                <td><code>{string_info['string'][:100]}...</code></td>
                                <td>{string_info['keyword_matched']}</td>
                                <td class="{risk_class}">{string_info['risk_level']}</td>
                            </tr>
                            """
                        html += "</table>"
                
                elif tool_name == "hexdump":
                    html += f"""
                    <p><strong>Total Bytes:</strong> {results.get('total_bytes', 0)}</p>
                    <div class="code-block">
                        <pre>{'<br>'.join(results.get('hex_preview', [])[:20])}</pre>
                    </div>
                    """
                
                elif tool_name == "pattern_analysis":
                    patterns = results.get('patterns_found', {})
                    if patterns:
                        html += "<table><tr><th>Pattern Type</th><th>Count</th><th>Examples</th></tr>"
                        for pattern_type, pattern_data in patterns.items():
                            html += f"""
                            <tr>
                                <td>{pattern_type.replace('_', ' ').title()}</td>
                                <td>{pattern_data['count']}</td>
                                <td><code>{', '.join(pattern_data['matches'][:3])}</code></td>
                            </tr>
                            """
                        html += "</table>"
                    else:
                        html += "<p>No suspicious patterns detected.</p>"
                
                elif tool_name == "entropy":
                    html += f"""
                    <p><strong>Entropy Score:</strong> {results.get('entropy', 0):.2f}</p>
                    <p><strong>Entropy Level:</strong> {results.get('entropy_level', 'Unknown')}</p>
                    """
            else:
                html += f"<p class='status-failed'>Error: {results.get('error', 'Unknown error')}</p>"
        
        return html
    
    def generate_security_findings_html(self, security_findings):
        """Generate HTML for security findings section"""
        if not security_findings:
            return "<p>‚úÖ No security findings detected.</p>"
        
        html = f"<p>Found <strong>{len(security_findings)}</strong> security findings:</p>"
        
        for finding in security_findings:
            severity_class = f"severity-{finding['severity'].lower()}"
            html += f"""
            <div class="finding-card">
                <h4>{finding['type']} <span class="{severity_class}">[{finding['severity']}]</span></h4>
                <p><strong>Description:</strong> {finding['description']}</p>
                <p><strong>Impact:</strong> {finding['impact']}</p>
                <p><strong>Recommendation:</strong> {finding['recommendation']}</p>
            </div>
            """
        
        return html
    
    def generate_recommendations_html(self, recommendations):
        """Generate HTML for recommendations section"""
        if not recommendations:
            return "<p>No specific recommendations available.</p>"
        
        html = "<table><tr><th>Category</th><th>Recommendation</th><th>Priority</th><th>Rationale</th></tr>"
        
        for rec in recommendations:
            priority_class = f"priority-{rec['priority'].lower()}"
            html += f"""
            <tr>
                <td>{rec['category']}</td>
                <td>{rec['recommendation']}</td>
                <td class="{priority_class}">{rec['priority']}</td>
                <td>{rec['rationale']}</td>
            </tr>
            """
        
        html += "</table>"
        return html

    def run_complete_analysis(self, file_path):
        """Run complete reverse engineering analysis with real-time feedback"""
        try:
            # Print banner
            self.print_banner()
            
            # Setup environment
            self.print_progress("Setting up analysis environment...", "RUNNING")
            self.setup_environment()
            self.print_progress("Environment setup complete", "SUCCESS")
            
            # Copy target file
            self.print_progress(f"Copying target file: {file_path}", "RUNNING")
            target_path, filename = self.copy_target_file(file_path)
            self.print_progress("File copied to analysis directory", "SUCCESS")
            
            # Get file information
            self.print_progress("Extracting file metadata...", "RUNNING")
            self.results["file_info"] = self.get_file_info(target_path)
            self.results["metadata"]["target_file"] = file_path
            self.results["metadata"]["analysis_file"] = target_path
            
            # Show file analysis header
            self.show_file_analysis_header(filename, self.results["file_info"])
            self.print_progress("File metadata extraction complete", "SUCCESS")
            
            # Run all analysis tools
            analysis_tools = {
                "strings": self.run_strings_analysis,
                "hexdump": self.run_hexdump_analysis,
                "pattern_analysis": self.run_pattern_analysis,
                "entropy": self.run_entropy_analysis
            }
            
            for tool_name, tool_func in analysis_tools.items():
                print(f"[+] Running {tool_name} analysis...")
                try:
                    self.results["analysis_results"][tool_name] = tool_func(target_path)
                    time.sleep(0.5)  # Brief pause between tools
                except Exception as e:
                    print(f"[-] Error running {tool_name}: {str(e)}")
                    self.results["analysis_results"][tool_name] = {"error": str(e), "status": "failed"}
                    
            # Analyze security risks
            print("[+] Analyzing security risks...")
            self.results["security_findings"] = self.analyze_security_risks(self.results["analysis_results"])
            
            # Generate recommendations
            print("[+] Generating security recommendations...")
            self.results["recommendations"] = self.generate_recommendations(
                self.results["analysis_results"], 
                self.results["security_findings"]
            )
            
            # Calculate overall risk score
            high_risks = sum(1 for risk in self.results["security_findings"] if risk["severity"] == "HIGH")
            medium_risks = sum(1 for risk in self.results["security_findings"] if risk["severity"] == "MEDIUM")
            low_risks = sum(1 for risk in self.results["security_findings"] if risk["severity"] == "LOW")
            
            risk_score = (high_risks * 10) + (medium_risks * 5) + (low_risks * 1)
            
            self.results["risk_assessment"] = {
                "overall_risk_score": risk_score,
                "risk_level": "HIGH" if risk_score >= 20 else "MEDIUM" if risk_score >= 10 else "LOW",
                "high_severity_findings": high_risks,
                "medium_severity_findings": medium_risks,
                "low_severity_findings": low_risks
            }
            
            # Save JSON report
            json_filename = f"windows_analysis_{filename}_{self.timestamp}.json"
            json_path = os.path.join(self.reports_folder, json_filename)
            
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(self.results, f, indent=2, default=str, ensure_ascii=False)
                
            print(f"[+] JSON report saved: {json_path}")
            
            # Generate HTML report
            html_path = None
            html_content = self.generate_html_report(self.results)
            if html_content:
                html_filename = f"windows_analysis_{filename}_{self.timestamp}.html"
                html_path = os.path.join(self.reports_folder, html_filename)
                
                with open(html_path, 'w', encoding='utf-8') as f:
                    f.write(html_content)
                    
                print(f"[+] HTML report saved: {html_path}")
                
            return {
                "json_report": json_path,
                "html_report": html_path,
                "results": self.results
            }
            
        except Exception as e:
            print(f"[-] Analysis failed: {str(e)}")
            return {"error": str(e)}

def main():
    parser = argparse.ArgumentParser(description="Windows-Compatible Complete Reverse Engineering Analyzer")
    parser.add_argument("file_path", help="Path to the file to analyze")
    parser.add_argument("--gemini-key", help="Gemini API key for HTML report generation")
    parser.add_argument("--output-dir", default="reports", help="Output directory for reports")
    
    args = parser.parse_args()
    
    # Initialize analyzer
    analyzer = WindowsReverseAnalyzer(gemini_api_key=args.gemini_key)
    
    if args.output_dir != "reports":
        analyzer.reports_folder = args.output_dir
        
    # Run analysis
    result = analyzer.run_complete_analysis(args.file_path)
    
    if "error" in result:
        print(f"[-] Analysis failed: {result['error']}")
        sys.exit(1)
    else:
        print("\n" + "="*80)
        print("üîç COMPREHENSIVE ANALYSIS COMPLETE")
        print("="*80)
        print(f"üìÑ JSON Report: {result['json_report']}")
        if result['html_report']:
            print(f"üåê HTML Report: {result['html_report']}")
        
        risk_assessment = result['results']['risk_assessment']
        print(f"‚ö†Ô∏è  Overall Risk Level: {risk_assessment['risk_level']}")
        print(f"üìä Risk Score: {risk_assessment['overall_risk_score']}")
        print(f"üî¥ High Severity: {risk_assessment['high_severity_findings']}")
        print(f"üü° Medium Severity: {risk_assessment['medium_severity_findings']}")
        print(f"üü¢ Low Severity: {risk_assessment['low_severity_findings']}")
        print(f"üí° Recommendations: {len(result['results']['recommendations'])}")
        print("="*80)

if __name__ == "__main__":
    main()