"""
ReverseGod Built-in String Extraction Tool
Custom implementation of 'strings' command functionality
"""

import re
from pathlib import Path
from typing import List, Dict, Any, Iterator
import codecs

class RGStrings:
    """Built-in string extraction tool"""
    
    def __init__(self):
        self.encodings = ['ascii', 'utf-8', 'utf-16le', 'utf-16be', 'latin1']
    
    def extract_strings(self, file_path: Path, min_length: int = 4, 
                       max_strings: int = 10000, include_unicode: bool = True) -> List[Dict[str, Any]]:
        """Extract strings from binary file"""
        try:
            with open(file_path, 'rb') as f:
                data = f.read()
            
            strings = []
            
            # Extract ASCII strings
            ascii_strings = self._extract_ascii_strings(data, min_length)
            for string_info in ascii_strings:
                strings.append({
                    'string': string_info['string'],
                    'offset': string_info['offset'],
                    'encoding': 'ascii',
                    'length': len(string_info['string'])
                })
            
            if include_unicode:
                # Extract Unicode strings
                unicode_strings = self._extract_unicode_strings(data, min_length)
                for string_info in unicode_strings:
                    strings.append({
                        'string': string_info['string'],
                        'offset': string_info['offset'],
                        'encoding': string_info['encoding'],
                        'length': len(string_info['string'])
                    })
            
            # Remove duplicates and sort by offset
            unique_strings = {}
            for s in strings:
                key = (s['string'], s['encoding'])
                if key not in unique_strings or s['offset'] < unique_strings[key]['offset']:
                    unique_strings[key] = s
            
            result = list(unique_strings.values())
            result.sort(key=lambda x: x['offset'])
            
            return result[:max_strings]
            
        except Exception as e:
            return []
    
    def _extract_ascii_strings(self, data: bytes, min_length: int) -> List[Dict[str, Any]]:
        """Extract ASCII strings from binary data"""
        strings = []
        
        # Pattern for printable ASCII characters
        pattern = rb'[\x20-\x7E]{' + str(min_length).encode() + rb',}'
        
        for match in re.finditer(pattern, data):
            try:
                string = match.group().decode('ascii')
                strings.append({
                    'string': string,
                    'offset': match.start(),
                    'encoding': 'ascii'
                })
            except UnicodeDecodeError:
                continue
        
        return strings
    
    def _extract_unicode_strings(self, data: bytes, min_length: int) -> List[Dict[str, Any]]:
        """Extract Unicode strings from binary data"""
        strings = []
        
        # UTF-16 Little Endian
        utf16le_strings = self._extract_utf16_strings(data, min_length, 'utf-16le')
        strings.extend(utf16le_strings)
        
        # UTF-16 Big Endian
        utf16be_strings = self._extract_utf16_strings(data, min_length, 'utf-16be')
        strings.extend(utf16be_strings)
        
        # UTF-8
        utf8_strings = self._extract_utf8_strings(data, min_length)
        strings.extend(utf8_strings)
        
        return strings
    
    def _extract_utf16_strings(self, data: bytes, min_length: int, encoding: str) -> List[Dict[str, Any]]:
        """Extract UTF-16 strings"""
        strings = []
        
        # Look for UTF-16 patterns (alternating bytes with nulls)
        if encoding == 'utf-16le':
            # Little endian: ASCII char followed by null
            pattern = rb'(?:[\x20-\x7E]\x00){' + str(min_length).encode() + rb',}'
        else:
            # Big endian: null followed by ASCII char
            pattern = rb'(?:\x00[\x20-\x7E]){' + str(min_length).encode() + rb',}'
        
        for match in re.finditer(pattern, data):
            try:
                string = match.group().decode(encoding).rstrip('\x00')
                if len(string) >= min_length:
                    strings.append({
                        'string': string,
                        'offset': match.start(),
                        'encoding': encoding
                    })
            except UnicodeDecodeError:
                continue
        
        return strings
    
    def _extract_utf8_strings(self, data: bytes, min_length: int) -> List[Dict[str, Any]]:
        """Extract UTF-8 strings"""
        strings = []
        
        # Look for valid UTF-8 sequences
        i = 0
        while i < len(data):
            start = i
            string_bytes = bytearray()
            
            while i < len(data):
                byte = data[i]
                
                # Check if this could be start of UTF-8 character
                if byte < 0x80:  # ASCII
                    if 0x20 <= byte <= 0x7E:  # Printable ASCII
                        string_bytes.append(byte)
                        i += 1
                    else:
                        break
                elif byte < 0xC0:  # Invalid start byte
                    break
                elif byte < 0xE0:  # 2-byte sequence
                    if i + 1 < len(data) and 0x80 <= data[i + 1] < 0xC0:
                        string_bytes.extend(data[i:i + 2])
                        i += 2
                    else:
                        break
                elif byte < 0xF0:  # 3-byte sequence
                    if (i + 2 < len(data) and 
                        0x80 <= data[i + 1] < 0xC0 and 
                        0x80 <= data[i + 2] < 0xC0):
                        string_bytes.extend(data[i:i + 3])
                        i += 3
                    else:
                        break
                elif byte < 0xF8:  # 4-byte sequence
                    if (i + 3 < len(data) and 
                        0x80 <= data[i + 1] < 0xC0 and 
                        0x80 <= data[i + 2] < 0xC0 and 
                        0x80 <= data[i + 3] < 0xC0):
                        string_bytes.extend(data[i:i + 4])
                        i += 4
                    else:
                        break
                else:
                    break
            
            # Try to decode the collected bytes
            if len(string_bytes) >= min_length:
                try:
                    string = string_bytes.decode('utf-8')
                    # Filter out strings that are just ASCII (already found)
                    if any(ord(c) > 127 for c in string):
                        strings.append({
                            'string': string,
                            'offset': start,
                            'encoding': 'utf-8'
                        })
                except UnicodeDecodeError:
                    pass
            
            if i == start:  # Avoid infinite loop
                i += 1
        
        return strings
    
    def get_strings_output(self, file_path: Path, min_length: int = 4, 
                          print_offset: bool = False, encoding_filter: str = None) -> str:
        """Get strings output in format similar to 'strings' command"""
        strings = self.extract_strings(file_path, min_length)
        
        if encoding_filter:
            strings = [s for s in strings if s['encoding'] == encoding_filter]
        
        output_lines = []
        for string_info in strings:
            if print_offset:
                output_lines.append(f"{string_info['offset']:8x} {string_info['string']}")
            else:
                output_lines.append(string_info['string'])
        
        return '\n'.join(output_lines)
    
    def analyze_strings(self, file_path: Path, min_length: int = 4) -> Dict[str, Any]:
        """Analyze strings and provide statistics"""
        strings = self.extract_strings(file_path, min_length)
        
        if not strings:
            return {
                'total_strings': 0,
                'encodings': {},
                'average_length': 0,
                'longest_string': '',
                'suspicious_strings': []
            }
        
        # Calculate statistics
        encodings = {}
        lengths = []
        suspicious_patterns = [
            r'[a-zA-Z]:\\.*\.exe',  # Windows paths
            r'/bin/.*',             # Unix paths
            r'https?://.*',         # URLs
            r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}',  # Email
            r'password|passwd|pwd', # Password related
            r'key|secret|token',    # Secrets
            r'admin|root|user',     # User accounts
            r'cmd|shell|bash',      # Shell commands
        ]
        
        suspicious_strings = []
        longest_string = ''
        
        for string_info in strings:
            string = string_info['string']
            encoding = string_info['encoding']
            
            # Count encodings
            encodings[encoding] = encodings.get(encoding, 0) + 1
            
            # Track lengths
            lengths.append(len(string))
            
            # Find longest string
            if len(string) > len(longest_string):
                longest_string = string
            
            # Check for suspicious patterns
            for pattern in suspicious_patterns:
                if re.search(pattern, string, re.IGNORECASE):
                    suspicious_strings.append({
                        'string': string,
                        'offset': string_info['offset'],
                        'pattern': pattern,
                        'encoding': encoding
                    })
                    break
        
        return {
            'total_strings': len(strings),
            'encodings': encodings,
            'average_length': sum(lengths) / len(lengths) if lengths else 0,
            'longest_string': longest_string,
            'suspicious_strings': suspicious_strings[:20]  # Limit to top 20
        }