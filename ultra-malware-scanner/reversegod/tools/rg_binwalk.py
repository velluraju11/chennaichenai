"""
ReverseGod Built-in Binwalk Tool
Custom implementation of 'binwalk' command functionality for firmware analysis
"""

import struct
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple
import re
import zlib
import hashlib

class RGBinwalk:
    """Built-in firmware analysis and signature scanning tool"""
    
    def __init__(self):
        self.signatures = self._load_signatures()
        self.entropy_threshold = 0.8
    
    def analyze_firmware(self, file_path: Path, extract: bool = False, 
                        signature_scan: bool = True) -> Dict[str, Any]:
        """Analyze firmware file for embedded signatures and structures"""
        try:
            with open(file_path, 'rb') as f:
                data = f.read()
            
            results = {
                "file_path": str(file_path),
                "file_size": len(data),
                "signatures_found": [],
                "entropy_analysis": {},
                "embedded_files": [],
                "compression_analysis": {},
                "analysis_complete": True
            }
            
            if signature_scan:
                results["signatures_found"] = self._scan_signatures(data)
            
            results["entropy_analysis"] = self._analyze_entropy(data)
            results["embedded_files"] = self._find_embedded_files(data)
            results["compression_analysis"] = self._analyze_compression(data)
            
            if extract:
                results["extracted_files"] = self._extract_files(data, file_path)
            
            return results
            
        except Exception as e:
            return {"error": f"Binwalk analysis failed: {str(e)}"}
    
    def _load_signatures(self) -> List[Dict[str, Any]]:
        """Load firmware and file signatures"""
        return [
            # Firmware signatures
            {
                "name": "U-Boot",
                "signature": b'\x27\x05\x19\x56',
                "description": "U-Boot uImage header",
                "offset_type": "fixed"
            },
            {
                "name": "LZMA",
                "signature": b'\x5d\x00\x00',
                "description": "LZMA compressed data",
                "offset_type": "any"
            },
            {
                "name": "Squashfs",
                "signature": b'hsqs',
                "description": "Squashfs filesystem, little endian",
                "offset_type": "any"
            },
            {
                "name": "Squashfs BE",
                "signature": b'sqsh',
                "description": "Squashfs filesystem, big endian",
                "offset_type": "any"
            },
            {
                "name": "JFFS2",
                "signature": b'\x19\x85',
                "description": "JFFS2 filesystem",
                "offset_type": "any"
            },
            {
                "name": "CRAMFS",
                "signature": b'\x45\x3d\xcd\x28',
                "description": "Cramfs filesystem",
                "offset_type": "any"
            },
            {
                "name": "YAFFS",
                "signature": b'\x03\x00\x00\x00\x01\x00\x00\x00\xff\xff',
                "description": "YAFFS filesystem",
                "offset_type": "any"
            },
            
            # Archive formats
            {
                "name": "ZIP",
                "signature": b'PK\x03\x04',
                "description": "ZIP archive",
                "offset_type": "any"
            },
            {
                "name": "RAR",
                "signature": b'Rar!\x1a\x07\x00',
                "description": "RAR archive",
                "offset_type": "any"
            },
            {
                "name": "7ZIP",
                "signature": b'7z\xbc\xaf\x27\x1c',
                "description": "7-Zip archive",
                "offset_type": "any"
            },
            {
                "name": "TAR",
                "signature": b'ustar',
                "description": "POSIX tar archive",
                "offset_type": "fixed",
                "offset": 257
            },
            
            # Compression formats
            {
                "name": "GZIP",
                "signature": b'\x1f\x8b\x08',
                "description": "gzip compressed data",
                "offset_type": "any"
            },
            {
                "name": "BZIP2",
                "signature": b'BZ',
                "description": "bzip2 compressed data",
                "offset_type": "any"
            },
            {
                "name": "XZ",
                "signature": b'\xfd7zXZ\x00',
                "description": "XZ compressed data",
                "offset_type": "any"
            },
            
            # Executable formats
            {
                "name": "ELF",
                "signature": b'\x7fELF',
                "description": "ELF executable",
                "offset_type": "any"
            },
            {
                "name": "PE",
                "signature": b'MZ',
                "description": "PE executable",
                "offset_type": "any"
            },
            
            # Image formats
            {
                "name": "JPEG",
                "signature": b'\xff\xd8\xff',
                "description": "JPEG image",
                "offset_type": "any"
            },
            {
                "name": "PNG",
                "signature": b'\x89PNG\r\n\x1a\n',
                "description": "PNG image",
                "offset_type": "any"
            },
            {
                "name": "GIF",
                "signature": b'GIF8',
                "description": "GIF image",
                "offset_type": "any"
            },
            
            # Certificate and crypto
            {
                "name": "X509",
                "signature": b'\x30\x82',
                "description": "X.509 certificate",
                "offset_type": "any"
            },
            {
                "name": "PEM",
                "signature": b'-----BEGIN',
                "description": "PEM certificate/key",
                "offset_type": "any"
            },
            
            # Bootloaders
            {
                "name": "GRUB",
                "signature": b'GRUB',
                "description": "GRUB bootloader",
                "offset_type": "any"
            },
            {
                "name": "LILO",
                "signature": b'LILO',
                "description": "LILO bootloader",
                "offset_type": "any"
            }
        ]
    
    def _scan_signatures(self, data: bytes) -> List[Dict[str, Any]]:
        """Scan for known signatures in firmware data"""
        found_signatures = []
        
        for sig in self.signatures:
            signature = sig["signature"]
            
            if sig["offset_type"] == "fixed":
                # Check at specific offset
                offset = sig.get("offset", 0)
                if (len(data) > offset + len(signature) and 
                    data[offset:offset + len(signature)] == signature):
                    found_signatures.append({
                        "name": sig["name"],
                        "description": sig["description"],
                        "offset": offset,
                        "size": len(signature),
                        "confidence": 95
                    })
            else:
                # Scan entire file
                offset = 0
                while True:
                    pos = data.find(signature, offset)
                    if pos == -1:
                        break
                    
                    # Validate signature context
                    confidence = self._validate_signature_context(data, pos, sig)
                    
                    if confidence > 50:  # Only report high-confidence matches
                        found_signatures.append({
                            "name": sig["name"],
                            "description": sig["description"],
                            "offset": pos,
                            "size": self._estimate_structure_size(data, pos, sig),
                            "confidence": confidence
                        })
                    
                    offset = pos + 1
        
        # Sort by offset
        found_signatures.sort(key=lambda x: x["offset"])
        return found_signatures
    
    def _validate_signature_context(self, data: bytes, offset: int, sig: Dict[str, Any]) -> int:
        """Validate signature based on surrounding context"""
        confidence = 70  # Base confidence
        
        # Check for common false positives
        if sig["name"] in ["ZIP", "RAR", "GZIP"]:
            # Validate archive headers
            if self._validate_archive_header(data, offset, sig["name"]):
                confidence = 90
            else:
                confidence = 30
        
        elif sig["name"] in ["ELF", "PE"]:
            # Validate executable headers
            if self._validate_executable_header(data, offset, sig["name"]):
                confidence = 95
            else:
                confidence = 40
        
        elif sig["name"] in ["JPEG", "PNG", "GIF"]:
            # Validate image headers
            if self._validate_image_header(data, offset, sig["name"]):
                confidence = 90
            else:
                confidence = 50
        
        return confidence
    
    def _validate_archive_header(self, data: bytes, offset: int, format_name: str) -> bool:
        """Validate archive format headers"""
        try:
            if format_name == "ZIP" and len(data) > offset + 30:
                # Check ZIP local file header structure
                header = struct.unpack('<I2H3I2H', data[offset:offset + 30])
                return header[1] <= 63  # Version should be reasonable
            
            elif format_name == "RAR" and len(data) > offset + 7:
                # RAR signature is pretty unique
                return True
            
            elif format_name == "GZIP" and len(data) > offset + 10:
                # Check GZIP header
                return data[offset + 3] <= 31  # Flags should be reasonable
            
        except (struct.error, IndexError):
            pass
        
        return False
    
    def _validate_executable_header(self, data: bytes, offset: int, format_name: str) -> bool:
        """Validate executable format headers"""
        try:
            if format_name == "ELF" and len(data) > offset + 16:
                # Check ELF header
                ei_class = data[offset + 4]
                ei_data = data[offset + 5]
                return ei_class in [1, 2] and ei_data in [1, 2]
            
            elif format_name == "PE" and len(data) > offset + 64:
                # Check DOS header
                if len(data) > offset + 60:
                    pe_offset = struct.unpack('<I', data[offset + 60:offset + 64])[0]
                    if offset + pe_offset + 4 < len(data):
                        return data[offset + pe_offset:offset + pe_offset + 4] == b'PE\x00\x00'
            
        except (struct.error, IndexError):
            pass
        
        return False
    
    def _validate_image_header(self, data: bytes, offset: int, format_name: str) -> bool:
        """Validate image format headers"""
        try:
            if format_name == "JPEG":
                # JPEG should have proper markers
                return len(data) > offset + 4 and data[offset + 1] in [0xd8, 0xe0, 0xe1]
            
            elif format_name == "PNG":
                # PNG signature is very specific
                return True
            
            elif format_name == "GIF":
                # Check GIF version
                return len(data) > offset + 6 and data[offset + 4:offset + 6] in [b'7a', b'9a']
            
        except IndexError:
            pass
        
        return False
    
    def _estimate_structure_size(self, data: bytes, offset: int, sig: Dict[str, Any]) -> int:
        """Estimate the size of the detected structure"""
        try:
            if sig["name"] == "ZIP":
                return self._estimate_zip_size(data, offset)
            elif sig["name"] == "GZIP":
                return self._estimate_gzip_size(data, offset)
            elif sig["name"] == "ELF":
                return self._estimate_elf_size(data, offset)
            elif sig["name"] == "PE":
                return self._estimate_pe_size(data, offset)
            else:
                # Default estimation based on entropy change
                return self._estimate_by_entropy(data, offset)
        except:
            return len(sig["signature"])
    
    def _estimate_zip_size(self, data: bytes, offset: int) -> int:
        """Estimate ZIP archive size"""
        try:
            # Look for end of central directory record
            eocd_sig = b'PK\x05\x06'
            pos = data.find(eocd_sig, offset)
            if pos != -1:
                return pos - offset + 22  # EOCD record size
        except:
            pass
        return 1024  # Default estimate
    
    def _estimate_gzip_size(self, data: bytes, offset: int) -> int:
        """Estimate GZIP compressed data size"""
        try:
            # GZIP trailer contains original size
            if len(data) >= offset + 10:
                # Skip header, find trailer
                pos = offset + 10
                while pos < len(data) - 8:
                    if data[pos:pos + 4] == b'\x00\x00\x00\x00':  # Possible trailer
                        orig_size = struct.unpack('<I', data[pos + 4:pos + 8])[0]
                        if orig_size < 1024 * 1024 * 100:  # Reasonable size
                            return pos - offset + 8
                    pos += 1
        except:
            pass
        return 1024  # Default estimate
    
    def _estimate_elf_size(self, data: bytes, offset: int) -> int:
        """Estimate ELF file size"""
        try:
            if len(data) >= offset + 64:  # Minimum ELF header
                # Get section header info
                ei_class = data[offset + 4]
                if ei_class == 1:  # 32-bit
                    shoff = struct.unpack('<I', data[offset + 32:offset + 36])[0]
                    shnum = struct.unpack('<H', data[offset + 48:offset + 50])[0]
                    shentsize = struct.unpack('<H', data[offset + 46:offset + 48])[0]
                else:  # 64-bit
                    shoff = struct.unpack('<Q', data[offset + 40:offset + 48])[0]
                    shnum = struct.unpack('<H', data[offset + 60:offset + 62])[0]
                    shentsize = struct.unpack('<H', data[offset + 58:offset + 60])[0]
                
                if shoff > 0 and shnum > 0:
                    return shoff + (shnum * shentsize) - offset
        except:
            pass
        return 4096  # Default estimate
    
    def _estimate_pe_size(self, data: bytes, offset: int) -> int:
        """Estimate PE file size"""
        try:
            if len(data) >= offset + 64:
                pe_offset = struct.unpack('<I', data[offset + 60:offset + 64])[0]
                if offset + pe_offset + 24 < len(data):
                    # Get size of image
                    size_of_image = struct.unpack('<I', 
                        data[offset + pe_offset + 80:offset + pe_offset + 84])[0]
                    if size_of_image < 1024 * 1024 * 100:  # Reasonable size
                        return size_of_image
        except:
            pass
        return 4096  # Default estimate
    
    def _estimate_by_entropy(self, data: bytes, offset: int) -> int:
        """Estimate structure size by entropy analysis"""
        chunk_size = 1024
        base_entropy = self._calculate_chunk_entropy(data[offset:offset + chunk_size])
        
        pos = offset + chunk_size
        while pos < len(data):
            chunk_entropy = self._calculate_chunk_entropy(data[pos:pos + chunk_size])
            if abs(chunk_entropy - base_entropy) > 1.0:  # Significant entropy change
                return pos - offset
            pos += chunk_size
        
        return min(8192, len(data) - offset)  # Default max estimate
    
    def _analyze_entropy(self, data: bytes, chunk_size: int = 1024) -> Dict[str, Any]:
        """Analyze entropy across the firmware"""
        entropy_map = []
        high_entropy_regions = []
        
        for i in range(0, len(data), chunk_size):
            chunk = data[i:i + chunk_size]
            if len(chunk) < chunk_size // 2:  # Skip small chunks
                break
            
            entropy = self._calculate_chunk_entropy(chunk)
            entropy_map.append({
                "offset": i,
                "entropy": entropy,
                "size": len(chunk)
            })
            
            if entropy > self.entropy_threshold:
                high_entropy_regions.append({
                    "offset": i,
                    "size": len(chunk),
                    "entropy": entropy,
                    "description": "Possible compressed/encrypted data"
                })
        
        return {
            "entropy_map": entropy_map[:100],  # Limit output
            "high_entropy_regions": high_entropy_regions,
            "average_entropy": sum(e["entropy"] for e in entropy_map) / len(entropy_map) if entropy_map else 0
        }
    
    def _calculate_chunk_entropy(self, chunk: bytes) -> float:
        """Calculate Shannon entropy of a data chunk"""
        if not chunk:
            return 0.0
        
        # Count byte frequencies
        byte_counts = [0] * 256
        for byte in chunk:
            byte_counts[byte] += 1
        
        # Calculate entropy
        entropy = 0.0
        chunk_len = len(chunk)
        
        for count in byte_counts:
            if count > 0:
                probability = count / chunk_len
                entropy -= probability * (probability.bit_length() - 1)
        
        return entropy
    
    def _find_embedded_files(self, data: bytes) -> List[Dict[str, Any]]:
        """Find embedded files within firmware"""
        embedded_files = []
        
        # Look for common embedded file patterns
        patterns = [
            (b'<!DOCTYPE html', "HTML document"),
            (b'<html', "HTML document"),
            (b'<?xml', "XML document"),
            (b'{\n  "', "JSON document"),
            (b'#!/bin/sh', "Shell script"),
            (b'#!/bin/bash', "Bash script"),
            (b'-----BEGIN CERTIFICATE', "X.509 Certificate"),
            (b'-----BEGIN PRIVATE KEY', "Private Key"),
            (b'ssh-rsa', "SSH Public Key"),
            (b'ssh-dss', "SSH Public Key")
        ]
        
        for pattern, description in patterns:
            offset = 0
            while True:
                pos = data.find(pattern, offset)
                if pos == -1:
                    break
                
                # Estimate file size
                end_pos = self._find_text_file_end(data, pos)
                size = end_pos - pos
                
                if size > 10:  # Minimum reasonable size
                    embedded_files.append({
                        "type": description,
                        "offset": pos,
                        "size": size,
                        "preview": data[pos:pos + 100].decode('utf-8', errors='ignore')
                    })
                
                offset = pos + 1
        
        return embedded_files[:20]  # Limit results
    
    def _find_text_file_end(self, data: bytes, start: int) -> int:
        """Find the end of a text file"""
        pos = start
        null_count = 0
        
        while pos < len(data) and pos < start + 10240:  # Max 10KB
            if data[pos] == 0:
                null_count += 1
                if null_count > 10:  # Too many nulls, probably end of text
                    break
            else:
                null_count = 0
            pos += 1
        
        return pos
    
    def _analyze_compression(self, data: bytes) -> Dict[str, Any]:
        """Analyze compression characteristics"""
        compression_info = {
            "compressed_regions": [],
            "compression_ratio_estimate": 0.0,
            "algorithms_detected": []
        }
        
        # Test for common compression algorithms
        algorithms = [
            ("ZLIB", self._test_zlib_compression),
            ("GZIP", self._test_gzip_compression),
            ("LZMA", self._test_lzma_compression)
        ]
        
        for name, test_func in algorithms:
            if test_func(data):
                compression_info["algorithms_detected"].append(name)
        
        # Estimate overall compression ratio
        try:
            compressed = zlib.compress(data[:8192])  # Test first 8KB
            compression_info["compression_ratio_estimate"] = len(compressed) / 8192
        except:
            compression_info["compression_ratio_estimate"] = 1.0
        
        return compression_info
    
    def _test_zlib_compression(self, data: bytes) -> bool:
        """Test if data contains ZLIB compressed content"""
        # Look for ZLIB header patterns
        for i in range(0, min(len(data), 1024), 1):
            if i + 2 < len(data):
                header = data[i:i + 2]
                if header[0] & 0x0f == 8:  # Deflate method
                    if (header[0] * 256 + header[1]) % 31 == 0:  # Valid checksum
                        return True
        return False
    
    def _test_gzip_compression(self, data: bytes) -> bool:
        """Test if data contains GZIP compressed content"""
        return b'\x1f\x8b\x08' in data[:1024]
    
    def _test_lzma_compression(self, data: bytes) -> bool:
        """Test if data contains LZMA compressed content"""
        return b'\x5d\x00\x00' in data[:1024]
    
    def _extract_files(self, data: bytes, base_path: Path) -> List[Dict[str, Any]]:
        """Extract embedded files (simulation)"""
        extracted = []
        
        # This would normally extract files to disk
        # For now, we'll just report what would be extracted
        signatures = self._scan_signatures(data)
        
        for sig in signatures:
            if sig["confidence"] > 80:
                extracted.append({
                    "name": f"{sig['name']}_{sig['offset']:08x}",
                    "type": sig["description"],
                    "offset": sig["offset"],
                    "size": sig["size"],
                    "extracted": False,  # Would be True if actually extracted
                    "reason": "Simulation mode - file not actually extracted"
                })
        
        return extracted
    
    def get_binwalk_output(self, file_path: Path, extract: bool = False) -> str:
        """Get output in binwalk format"""
        result = self.analyze_firmware(file_path, extract)
        
        if "error" in result:
            return f"binwalk: {result['error']}"
        
        output_lines = []
        output_lines.append(f"\nDECIMAL       HEXADECIMAL     DESCRIPTION")
        output_lines.append("-" * 80)
        
        for sig in result.get("signatures_found", []):
            output_lines.append(f"{sig['offset']:<13} 0x{sig['offset']:X:<11} {sig['description']}")
        
        # Add entropy analysis
        if result.get("entropy_analysis", {}).get("high_entropy_regions"):
            output_lines.append("\nHigh entropy regions (possible compression/encryption):")
            for region in result["entropy_analysis"]["high_entropy_regions"][:5]:
                output_lines.append(f"{region['offset']:<13} 0x{region['offset']:X:<11} "
                                  f"High entropy region (entropy: {region['entropy']:.2f})")
        
        return "\n".join(output_lines)